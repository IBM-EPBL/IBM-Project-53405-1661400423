{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "MODEL BUILDING\n",
        "\n",
        "Compile To The Model"
      ],
      "metadata": {
        "id": "me_zbeGD6Pzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image \n",
        "import ImageDataGenerator"
      ],
      "metadata": {
        "id": "zYs-_4dld3OK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "JdWdxtr8c9Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating sample sourcecode to multiply two variables\n",
        "# x and y.\n",
        "srcCode = 'x = 10\\ny = 20\\nmul = x * y\\nprint(\"mul =\", mul)'\n",
        " \n",
        "# Converting above source code to an executable\n",
        "execCode = compile(srcCode, 'mulstring', 'exec')\n",
        " \n",
        "# Running the executable code.\n",
        "exec(execCode)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pcJMORT6roa",
        "outputId": "836b6f0d-f85b-420a-d444-e7d3cc218f84"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mul = 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Datagen\n",
        "train_datagen = ImageDataGenerator(rescale=1/255,zoom_range=0.2,horizontal_flip=True,vertical_flip=False)\n",
        "# Testing Datagen\n",
        "test_datagen = ImageDataGenerator(rescale=1/255)"
      ],
      "metadata": {
        "id": "2eEtAcwydBWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Dataset\n",
        "x_train=train_datagen.flow_from_directory(r'/content/drive/MyDrive/Dataset/training_set',target_size=(64,64), class_mode='categorical',batch_size=900)\n",
        "# Testing Dataset\n",
        "x_test=test_datagen.flow_from_directory(r'/content/drive/MyDrive/Dataset/test_set',target_size=(64,64), class_mode='categorical',batch_size=900)"
      ],
      "metadata": {
        "id": "C_9Du0NFdNRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_model_results(model, root=\"./\"):\n",
        "\n",
        "    listing = glob.glob(root + '/models/' + model + '/*/best_pars.pkl')\n",
        "\n",
        "    dic_list = []\n",
        "    for file in listing:\n",
        "        tmp = hyper_parameters_load(file)\n",
        "        dic_list.append(tmp.to_dictionary())\n",
        "\n",
        "    df = pd.DataFrame(dic_list)\n",
        "    df['diff'] = df.test_F1 - df.forecast_F1\n",
        "    df['pci'] = abs(df.test_F1 - df.forecast_F1)\n",
        "\n",
        "    if not os.path.exists(root + '/figures/' +  model ):\n",
        "        os.makedirs(root + '/figures/' +  model )\n",
        "\n",
        "    df.to_csv(root + '/figures/' +  model + '/results.csv', index=False)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "3em1Bhjt7M7H"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set optimizer loss and metrics\n",
        "    opt = Adam(lr=args.initial_lr, beta_1=0.99, beta_2=0.999, decay=1e-6)\n",
        "    if args.net.find('caps') != -1:\n",
        "        metrics = {'out_seg': dice_hard}\n",
        "    else:\n",
        "        metrics = [dice_hard]\n",
        "\n",
        "    loss, loss_weighting = get_loss(root=args.data_root_dir, split=args.split_num, net=args.net,\n",
        "                                    recon_wei=args.recon_wei, choice=args.loss)\n",
        "\n",
        "    # If using CPU or single GPU\n",
        "    if args.gpus <= 1:\n",
        "        uncomp_model.compile(optimizer=opt, loss=loss, loss_weights=loss_weighting, metrics=metrics)\n",
        "        return uncomp_model\n",
        "    # If using multiple GPUs\n",
        "    else:\n",
        "        with tf.device(\"/cpu:0\"):\n",
        "            uncomp_model.compile(optimizer=opt, loss=loss, loss_weights=loss_weighting, metrics=metrics)\n",
        "            model = multi_gpu_model(uncomp_model, gpus=args.gpus)\n",
        "            model.__setattr__('callback_model', uncomp_model)\n",
        "        model.compile(optimizer=opt, loss=loss, loss_weights=loss_weighting, metrics=metrics)\n",
        "\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "test_size = 0.33\n",
        "seed = 7\n",
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, \n",
        "random_state=seed)"
      ],
      "metadata": {
        "id": "REDASqRbdQ6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Len x-training : \", len(x_train))\n",
        "print(\"Len x-test : \", len(x_test))"
      ],
      "metadata": {
        "id": "5OLWnht2dnsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The Class Indices in Training Dataset\n",
        "x_train.class_indices"
      ],
      "metadata": {
        "id": "K3NDeMbWdq2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Compilation"
      ],
      "metadata": {
        "id": "jRwpGWtE7t8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense"
      ],
      "metadata": {
        "id": "h5gXZbjg7vpo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Model\n",
        "model=Sequential()"
      ],
      "metadata": {
        "id": "QjJznQD771A5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Layers\n",
        "model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,3)))"
      ],
      "metadata": {
        "id": "xGNcpmwG7_nY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "2IegBQNg8C_5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding Dense Layers\n",
        "model.add(Dense(300,activation='relu'))\n",
        "model.add(Dense(150,activation='relu'))\n",
        "model.add(Dense(9,activation='softmax'))"
      ],
      "metadata": {
        "id": "1hloajWF8F9U"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the Model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "bhMrziIA8I8k"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reading code from a file\n",
        "f = open('main.py', 'r')\n",
        "temp = f.read()\n",
        "f.close()\n",
        "\n",
        "code = compile(temp, 'main.py', 'exec')\n",
        "exec(code)"
      ],
      "metadata": {
        "id": "dbbqA3Q5dy3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAVING THE MODEL"
      ],
      "metadata": {
        "id": "u2dXDWh38SOu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('asl_model_84_54.h5')"
      ],
      "metadata": {
        "id": "jjLRwBln8cpU"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}